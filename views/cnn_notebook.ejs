<!DOCTYPE html>
<html>
    <head>
        <meta charset="utf-8" />
        <title><%= title %></title>
        <link rel="stylesheet" type="text/css" href="/stylesheets/styles.css">
        <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>
        <!-- Loading mathjax macro -->
        <!-- Load mathjax -->
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_HTML"></script>
        <!-- MathJax configuration -->
        <script type="text/x-mathjax-config" src="/javascript/script.js"></script>
        <!-- End of mathjax configuration -->
      </head>
<body>
  <div tabindex="-1" id="notebook" class="border-box-sizing">
    <div class="container" id="notebook-container">

<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Basic-CNN-using-Keras-(MNIST-dataset)">Basic CNN using Keras (MNIST dataset)<a class="anchor-link" href="#Basic-CNN-using-Keras-(MNIST-dataset)">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<h2 id="Requirements">Requirements<a class="anchor-link" href="#Requirements">&#182;</a></h2><ul>
<li><a href="https://www.python.org/">Python (version 3.6.x)</a></li>
<li><a href="https://www.scipy.org/">Scipy</a></li>
<li><a href="http://www.numpy.org/">Numpy</a></li>
<li><a href="https://pandas.pydata.org/">Pandas</a></li>
<li><a href="https://matplotlib.org/">Matplotlib</a></li>
<li><a href="https://seaborn.pydata.org/">Seaborn</a></li>
<li><a href="https://keras.io/">Keras</a></li>
<li><a href="https://www.tensorflow.org/">Tensorflow</a></li>
</ul>
<p>You can either download all of them seperately and install them, or you can use <a href="https://anaconda.org/">Anaconda</a> to get them easily however if you want to use Tensorflow training with GPU enabled then the installation is a little different. It is only useful if your GPU card has CUDA Compute Capability 3.0 or higher. Please refer to this <a href="https://developer.nvidia.com/cuda-gpus/">NVIDIA link</a> for your GPU compatibility and this is the <a href="https://www.tensorflow.org/install/">Tensorflow installation instructions</a></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<h2 id="Description">Description<a class="anchor-link" href="#Description">&#182;</a></h2><p>This is a 5 layers Sequential Convolutional Neural Network for digits recognition trained on MNIST dataset. It is build with Keras API (Tensorflow backend).</p>
<p>I achieved 99.5% to 99.6% accuracy with this CNN trained on Kaggle online Kernels. <strong>If you have an old system like mine (i7-3610QM @ 3.2Ghz, NVIDIA GeForce GT-630M) it is recommended to try on online systems or cloud. Otherwise your processor will get hot... really hot and the system might also shutdown.</strong></p>
<p>For the above reasons, I set the number of epochs to 1 (that only made my laptop quite hot), if you want to achieve 99%+ accuracy set it to any value above 20 and enjoy.</p>
<hr>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[1]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span> <span class="c1"># linear algebra</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span> <span class="c1"># data processing, CSV file I/O (e.g. pd.read_csv)</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span> <span class="c1">#beautiful graphs</span>

<span class="kn">import</span> <span class="nn">keras</span>
<span class="kn">from</span> <span class="nn">keras</span> <span class="k">import</span> <span class="n">backend</span> <span class="k">as</span> <span class="n">K</span>
<span class="kn">from</span> <span class="nn">keras.utils.np_utils</span> <span class="k">import</span> <span class="n">to_categorical</span> <span class="c1"># convert to one-hot-encoding</span>
<span class="kn">from</span> <span class="nn">keras.models</span> <span class="k">import</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="k">import</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">Dropout</span><span class="p">,</span> <span class="n">Flatten</span><span class="p">,</span> <span class="n">Conv2D</span><span class="p">,</span> <span class="n">MaxPool2D</span>
<span class="kn">from</span> <span class="nn">keras.optimizers</span> <span class="k">import</span> <span class="n">RMSprop</span>
<span class="kn">from</span> <span class="nn">keras.preprocessing.image</span> <span class="k">import</span> <span class="n">ImageDataGenerator</span>
<span class="kn">from</span> <span class="nn">keras.callbacks</span> <span class="k">import</span> <span class="n">ReduceLROnPlateau</span>

<span class="c1"># For splitting training and testing data</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="k">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="k">import</span> <span class="n">confusion_matrix</span>
<span class="kn">import</span> <span class="nn">itertools</span>
<span class="c1"># Put the input data files in the &quot;/input_data/&quot; directory.</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>Using TensorFlow backend.
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<p>Read and parse the data to check the number of samples of each set of images 0 to 9. We will only be using the training data for our training and validation. The test data will only be used when the model is ready for prediction.</p>
<hr>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[2]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">train</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;input_data/train.csv&quot;</span><span class="p">)</span>
<span class="n">test</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;input_data/test.csv&quot;</span><span class="p">)</span>

<span class="n">Y_train</span> <span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span>
<span class="c1"># Drop &#39;label&#39; column</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">train</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">],</span><span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span> 

<span class="c1"># free some space</span>
<span class="k">del</span> <span class="n">train</span> 

<span class="n">g</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">countplot</span><span class="p">(</span><span class="n">Y_train</span><span class="p">)</span>
<span class="n">Y_train</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[2]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>1    4684
7    4401
3    4351
9    4188
2    4177
6    4137
0    4132
4    4072
8    4063
5    3795
Name: label, dtype: int64</pre>
</div>

</div>

<div class="output_area">

<div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<p>I have done a very basic form of a grayscale normalization to reduce the effect of illumination's differences.
Moreover the CNN converg faster on [0...1] data than on [0...255].</p>
<p>Train and test images are of 28px x 28px which are stock in pandas and the dataframe are 1D vectors of 784 values. 
Reshape all data to 28x28x1 3D matrices.</p>
<p>Keras requires an extra dimension in the end which correspond to channels. MNIST images are gray scaled so it use only one channel. For RGB images, there is 3 channels, then the reshape will be 784px vectors to 28x28x3 3D matrices.</p>
<hr>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[3]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Normalize data</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">X_train</span> <span class="o">/</span> <span class="mf">255.0</span>
<span class="n">test</span> <span class="o">=</span> <span class="n">test</span> <span class="o">/</span> <span class="mf">255.0</span>
<span class="c1"># Reshaping image in 3 dimensions (height = 28px, width = 28px , canal = 1)</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="n">test</span> <span class="o">=</span> <span class="n">test</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Encoding labels to one hot vectors (ex : 2 -&gt; [0,0,1,0,0,0,0,0,0,0])</span>
<span class="n">Y_train</span> <span class="o">=</span> <span class="n">to_categorical</span><span class="p">(</span><span class="n">Y_train</span><span class="p">,</span> <span class="n">num_classes</span> <span class="o">=</span> <span class="mi">10</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<p>I chose to split the train set in two parts : a small fraction (10%) became the validation set which the model is evaluated and the rest (90%) is used to train the model.</p>
<p>Since we have 42,000 training images of balanced labels as per the earlier graph output, a random split of the train set doesn't cause some labels to be over represented in the validation set. <strong>Be carefull with some unbalanced dataset a simple random split could cause inaccurate evaluation during the validation.</strong></p>
<p>To avoid that, you could use stratify = True option in train_test_split function <strong>(Only for &gt;=0.17 sklearn versions).</strong></p>
<p>Also validation set is extremely important to test the overfit of any training samples</p>
<hr>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[4]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Setting random seed</span>
<span class="n">random_seed</span> <span class="o">=</span> <span class="mi">3</span>
<span class="c1"># Split the train and the validation set for the fitting</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_val</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">,</span> <span class="n">Y_val</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">,</span> <span class="n">test_size</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">random_seed</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<p>I used the Keras Sequential API, where you have just to add one layer at a time, starting from the input.</p>
<p>The first is the convolutional (Conv2D) layer. It is like a set of learnable filters. I choosed to set 32 filters for the two firsts conv2D layers and 64 filters for the two last ones <strong>(feel free to change these values and play around you may even achieve greater accuracy)</strong>. Each filter transforms a part of the image (defined by the kernel size) using the kernel filter. The kernel filter matrix is applied on the whole image. Filters can be seen as a transformation of the image.</p>
<p>The CNN can isolate features that are useful everywhere from these transformed images (feature maps).</p>
<p>The second important layer in CNN is the pooling (MaxPool2D) layer. This layer simply acts as a downsampling filter. It looks at the 2 neighboring pixels and picks the maximal value. These are used to reduce computational cost, and to some extent also reduce overfitting. We have to choose the pooling size (i.e the area size pooled each time) more the pooling dimension is high, more the downsampling is important.</p>
<p>Combining convolutional and pooling layers, CNN are able to combine local features and learn more global features of the image.</p>
<p>Dropout is a regularization method, where a proportion of nodes in the layer are randomly ignored (setting their wieghts to zero) for each training sample. This drops randomly a propotion of the network and forces the network to learn features in a distributed way. This technique also improves generalization and reduces the overfitting.</p>
<p>'<strong>relu</strong>' is the rectifier (activation function max(0,x) linear unit. The rectifier activation function is used to add non linearity to the network. You can also use <strong>sigmoid</strong> or <strong>tanh</strong>. <strong>Again play around with these there is no fixed method that will give you the highest accuracy it's mostly trial and error</strong></p>
<p>The Flatten layer is use to convert the final feature maps into a one single 1D vector. This flattening step is needed so that you can make use of fully connected layers after some convolutional/maxpool layers. It combines all the found local features of the previous convolutional layers.</p>
<p>In the end I used the features in two fully-connected (Dense) layers which is just artificial an neural networks (ANN) classifier. In the last layer(Dense(10, activation="softmax")) the net outputs distribution of probability of each class.</p>
<p><strong>Please read more about each such classes and functions in the references section.</strong></p>
<hr>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[5]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Set the CNN model </span>
<span class="c1"># my CNN architechture is </span>
<span class="c1">#    Input -&gt; [[Conv2D-&gt;relu]X2 -&gt; MaxPool2D -&gt; Dropout]X2 -&gt; Flatten -&gt; Dense -&gt; Dropout -&gt; Output</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>

<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span> <span class="o">=</span> <span class="mi">32</span><span class="p">,</span> <span class="n">kernel_size</span> <span class="o">=</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">),</span><span class="n">padding</span> <span class="o">=</span> <span class="s1">&#39;Same&#39;</span><span class="p">,</span> 
                 <span class="n">activation</span> <span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">input_shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">,</span><span class="mi">1</span><span class="p">)))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span> <span class="o">=</span> <span class="mi">32</span><span class="p">,</span> <span class="n">kernel_size</span> <span class="o">=</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">),</span><span class="n">padding</span> <span class="o">=</span> <span class="s1">&#39;Same&#39;</span><span class="p">,</span> 
                 <span class="n">activation</span> <span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">MaxPool2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">)))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.25</span><span class="p">))</span>


<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span> <span class="o">=</span> <span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span> <span class="o">=</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span><span class="n">padding</span> <span class="o">=</span> <span class="s1">&#39;Same&#39;</span><span class="p">,</span> 
                 <span class="n">activation</span> <span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span> <span class="o">=</span> <span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span> <span class="o">=</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span><span class="n">padding</span> <span class="o">=</span> <span class="s1">&#39;Same&#39;</span><span class="p">,</span> 
                 <span class="n">activation</span> <span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">MaxPool2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">),</span> <span class="n">strides</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">)))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.25</span><span class="p">))</span>


<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Flatten</span><span class="p">())</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="n">activation</span> <span class="o">=</span> <span class="s2">&quot;relu&quot;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.5</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span> <span class="o">=</span> <span class="s2">&quot;softmax&quot;</span><span class="p">))</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<p>Once the layers are added to the model, we need to set up a score function, a loss function and an optimisation algorithm.</p>
<p>We define the loss function to measure how poorly our model performs on images with known labels. It is the error rate between the oberved labels and the predicted ones. We use a specific form for categorical classifications (&gt;2 classes) called the "categorical_crossentropy". <strong>Further reading is advised</strong></p>
<p>The most important function is the optimizer. This function will iteratively improve parameters (filters kernel values, weights and bias of neurons ...) in order to minimise the loss.</p>
<p>I choosed RMSprop (with default values), it is a very effective optimizer. The RMSProp update adjusts the Adagrad method in a very simple way in an attempt to reduce its aggressive, monotonically decreasing learning rate. <strong>We could also have used Stochastic Gradient Descent ('sgd') optimizer, but it is slower than RMSprop. But really do give it a try you will literally notice the difference (I can't help technology is advancing everyday sorry Stochastic Gradient Descent)</strong></p>
<p>The metric function "accuracy" is used is to evaluate the performance our model. This metric function is similar to the loss function, except that the results from the metric evaluation are not used when training the model (only for evaluation).</p>
<hr>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[6]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Define the optimizer</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">RMSprop</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">rho</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="mf">1e-08</span><span class="p">,</span> <span class="n">decay</span><span class="o">=</span><span class="mf">0.0</span><span class="p">)</span>

<span class="c1"># Compile the model</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">optimizer</span> <span class="p">,</span> <span class="n">loss</span> <span class="o">=</span> <span class="s2">&quot;categorical_crossentropy&quot;</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">])</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<p><img src="http://cs231n.github.io/assets/nn3/learningrates.jpeg" alt="alt text" title="Comparision of learning rate">
In order to make the optimizer converge faster and closest to the global minimum of the loss function, I used an annealing method of the learning rate (LR).</p>
<p>The LR is the step by which the optimizer walks through the 'loss landscape'. The higher LR, the bigger are the steps and the quicker is the convergence. However the sampling is very poor with an high LR and the optimizer could probably fall into a local minima.</p>
<p>Its better to have a decreasing learning rate during the training to reach efficiently the global minimum of the loss function.</p>
<p>To keep the advantage of the fast computation time with a high LR, I decreased the LR dynamically every X steps (epochs) depending if it is necessary (when accuracy is not improved).</p>
<p>With the ReduceLROnPlateau function from Keras.callbacks, I choose to reduce the LR by half if the accuracy is not improved after 3 epochs.</p>
<hr>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[7]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Setting a learning rate annealer... this will change continuously</span>
<span class="n">learning_rate_reduction</span> <span class="o">=</span> <span class="n">ReduceLROnPlateau</span><span class="p">(</span><span class="n">monitor</span><span class="o">=</span><span class="s1">&#39;val_acc&#39;</span><span class="p">,</span> 
                                            <span class="n">patience</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> 
                                            <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> 
                                            <span class="n">factor</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> 
                                            <span class="n">min_lr</span><span class="o">=</span><span class="mf">0.0001</span><span class="p">)</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">1</span> <span class="c1"># Run for 25 or more epochs to get about 0.995 or 0.996 accuracy</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">128</span> <span class="c1"># Change the batch_size to see the effect</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<p>In order to avoid overfitting problem, we need to expand artificially our handwritten digit dataset. We can make your existing dataset even larger. The idea is to alter the training data with small transformations to reproduce the variations occuring when someone is writing a digit.</p>
<p>For example, the number is not centered The scale is not the same (some who write with big/small numbers) The image is rotated...</p>
<p>Approaches that alter the training data in ways that change the array representation while keeping the label the same are known as data augmentation techniques. Some popular augmentations people use are grayscales, horizontal flips, vertical flips, random crops, color jitters, translations, rotations, and much more.</p>
<p>By applying just a couple of these transformations to our training data, we can easily double or triple the number of training examples and create a very robust model.</p>
<p>The improvement is important :</p>
<ul>
<li>Without data augmentation 97% to 98% accuracy</li>
<li>With data augmentation 99% accuracy</li>
</ul>
<hr>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[8]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Data augmentation to prevent overfitting</span>
<span class="n">datagen</span> <span class="o">=</span> <span class="n">ImageDataGenerator</span><span class="p">(</span>
        <span class="n">featurewise_center</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>  <span class="c1"># set input mean to 0 over the dataset</span>
        <span class="n">samplewise_center</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>  <span class="c1"># set each sample mean to 0</span>
        <span class="n">featurewise_std_normalization</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>  <span class="c1"># divide inputs by std of the dataset</span>
        <span class="n">samplewise_std_normalization</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>  <span class="c1"># divide each input by its std</span>
        <span class="n">zca_whitening</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>  <span class="c1"># apply ZCA whitening</span>
        <span class="n">rotation_range</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>  <span class="c1"># randomly rotate images in the range (degrees, 0 to 180)</span>
        <span class="n">zoom_range</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span> <span class="c1"># Randomly zoom image </span>
        <span class="n">width_shift_range</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>  <span class="c1"># randomly shift images horizontally (fraction of total width)</span>
        <span class="n">height_shift_range</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>  <span class="c1"># randomly shift images vertically (fraction of total height)</span>
        <span class="n">horizontal_flip</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>  <span class="c1"># randomly flip images</span>
        <span class="n">vertical_flip</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>  <span class="c1"># randomly flip images</span>

<span class="n">datagen</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<p>For the data augmentation, I chose to :</p>
<ul>
<li>Randomly rotate some training images by 10 degrees</li>
<li>Randomly Zoom by 10% some training images</li>
<li>Randomly shift images horizontally by 10% of the width</li>
<li>Randomly shift images vertically by 10% of the height</li>
<li>I did not apply a vertical_flip nor horizontal_flip since it could have lead to misclassify symetrical numbers such as 6 and 9.</li>
</ul>
<p><strong>You may apply more operations and that may result in improving the result</strong></p>
<p>Once our model is ready, we fit the training dataset .</p>
<hr>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[9]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Fit the model</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit_generator</span><span class="p">(</span><span class="n">datagen</span><span class="o">.</span><span class="n">flow</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">Y_train</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">),</span>
                              <span class="n">epochs</span> <span class="o">=</span> <span class="n">epochs</span><span class="p">,</span> <span class="n">validation_data</span> <span class="o">=</span> <span class="p">(</span><span class="n">X_val</span><span class="p">,</span><span class="n">Y_val</span><span class="p">),</span>
                              <span class="n">verbose</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="n">steps_per_epoch</span><span class="o">=</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">//</span> <span class="n">batch_size</span>
                              <span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">learning_rate_reduction</span><span class="p">])</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch 1/1
 - 201s - loss: 0.4699 - acc: 0.8496 - val_loss: 0.0637 - val_acc: 0.9798
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[10]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Plot the loss and accuracy curves for training and validation </span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">matplotlib.image</span> <span class="k">as</span> <span class="nn">mpimg</span>
<span class="o">%</span><span class="k">matplotlib</span> inline

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Training loss&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;validation loss&quot;</span><span class="p">,</span><span class="n">axes</span> <span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">legend</span> <span class="o">=</span> <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;best&#39;</span><span class="p">,</span> <span class="n">shadow</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;acc&#39;</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Training accuracy&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_acc&#39;</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s2">&quot;Validation accuracy&quot;</span><span class="p">)</span>
<span class="n">legend</span> <span class="o">=</span> <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;best&#39;</span><span class="p">,</span> <span class="n">shadow</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<p>The code below is for plotting loss and accuracy curves for training and validation. Since, I have set only 1 epoch on this notebook. 
I will show you the training and validation curves I obtained from the model I built with 50 epochs (about 4h-30mins).
<img src="http://img1.imagilive.com/0218/__results___9_066c.png" alt="alt text" title="Loss and accuracy curves for training and validation"></p>
<p>The model reaches almost 98% accuracy on the validation dataset after 1 epoch. The validation accuracy is greater than the training accuracy almost evry time during the training. That means that our model dosen't not overfit the training set.</p>
<p>Conclusion: The model is pretty well trained.
<img src="http://img1.imagilive.com/0717/accuracies1de.jpg" alt="alt text" title="Comparision of accuracy and epochs"></p>
<hr>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[11]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># predict results</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test</span><span class="p">)</span>
<span class="c1"># select the indix with the maximum probability</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">results</span><span class="p">,</span><span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">results</span><span class="p">,</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;Label&quot;</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[12]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Convert to proper format to submit the test model results</span>
<span class="n">submission</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">28001</span><span class="p">),</span><span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;ImageId&quot;</span><span class="p">),</span><span class="n">results</span><span class="p">],</span><span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">submission</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s2">&quot;cnn_mnist_datagen.csv&quot;</span><span class="p">,</span><span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[13]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">submission</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>       ImageId  Label
0            1      2
1            2      0
2            3      9
3            4      0
4            5      3
5            6      9
6            7      0
7            8      3
8            9      0
9           10      3
10          11      5
11          12      7
12          13      4
13          14      0
14          15      4
15          16      3
16          17      3
17          18      1
18          19      9
19          20      0
20          21      9
21          22      1
22          23      1
23          24      5
24          25      7
25          26      4
26          27      2
27          28      7
28          29      4
29          30      7
...        ...    ...
27970    27971      5
27971    27972      0
27972    27973      4
27973    27974      8
27974    27975      0
27975    27976      3
27976    27977      6
27977    27978      0
27978    27979      1
27979    27980      9
27980    27981      3
27981    27982      1
27982    27983      1
27983    27984      0
27984    27985      4
27985    27986      5
27986    27987      2
27987    27988      2
27988    27989      9
27989    27990      6
27990    27991      7
27991    27992      6
27992    27993      7
27993    27994      9
27994    27995      7
27995    27996      9
27996    27997      7
27997    27998      3
27998    27999      9
27999    28000      2

[28000 rows x 2 columns]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<h2 id="References">References<a class="anchor-link" href="#References">&#182;</a></h2><p>Please show some love to these people :)</p>
<ul>
<li><a href="https://www.kaggle.com/yassineghouzam/introduction-to-cnn-keras-0-997-top-6/notebook">Kaggle user: Yassine Ghouzam</a> <strong>(The major part of this notebook is his I have merely adapted the network according to my use. I suggest you visit this link once the confusion matrix part is also discussed here)</strong></li>
<li><a href="http://cs231n.stanford.edu">CS231n: Convolutional Neural Networks for Visual Recognition</a> <strong>(Majority of the explanation and the two graphs are from here. Further study is highly suggested)</strong></li>
<li><a href="https://github.com/Kulbear/deep-learning-nano-foundation/wiki/ReLU-and-Softmax-Activation-Functions">ReLU and Softmax Activation Functions</a> <strong>(A nice description from Udacity course)</strong></li>
</ul>
<hr>

</div>
</div>
</div>
    </div>
  </div>
</body>

 


</html>
